import type {
  AIProvider,
  AIStreamChunk,
  AIProviderGenerateParams,
  AIProviderTransformParams,
} from '../provider-interface.js';

/**
 * EchoProvider â€” mock/dev AI provider for testing
 *
 * Generates content by echoing the prompt with some formatting.
 * Simulates streaming by yielding tokens with a small delay.
 */
export class EchoProvider implements AIProvider {
  readonly id = 'echo';
  readonly displayName = 'Echo (Development)';

  async *generate(params: AIProviderGenerateParams): AsyncIterable<AIStreamChunk> {
    const response = this.buildGenerateResponse(params.prompt, params.context);
    yield* this.streamResponse(response);
  }

  async *transform(params: AIProviderTransformParams): AsyncIterable<AIStreamChunk> {
    const response = this.buildTransformResponse(
      params.selectedText,
      params.instruction
    );
    yield* this.streamResponse(response);
  }

  async validateConfig(): Promise<boolean> {
    return true;
  }

  private buildGenerateResponse(prompt: string, context?: string): string {
    const lines = [
      `**AI Generated Content**\n`,
      `Based on your request: "${prompt.slice(0, 200)}${prompt.length > 200 ? '...' : ''}"`,
      '',
    ];

    if (context) {
      lines.push(`*Using document context (${context.length} chars)*\n`);
    }

    lines.push(
      'This is a development response from the Echo provider.',
      'In production, this would be generated by a real AI model.',
      '',
      `> ${prompt}`
    );

    return lines.join('\n');
  }

  private buildTransformResponse(selectedText: string, instruction: string): string {
    const lines = [
      `**Transformed Content** (${instruction})\n`,
      `Original (${selectedText.length} chars): "${selectedText.slice(0, 100)}${selectedText.length > 100 ? '...' : ''}"`,
      '',
      `*Applied: ${instruction}*\n`,
      selectedText,
    ];

    return lines.join('\n');
  }

  private async *streamResponse(text: string): AsyncIterable<AIStreamChunk> {
    // Simulate token-by-token streaming with word-level chunks
    const words = text.split(/(\s+)/);
    let totalTokens = 0;

    for (const word of words) {
      if (word.length > 0) {
        totalTokens++;
        yield { type: 'token', content: word };
        // Small delay to simulate streaming (10ms per token)
        await new Promise((resolve) => setTimeout(resolve, 10));
      }
    }

    yield {
      type: 'done',
      content: text,
      metadata: {
        tokensUsed: totalTokens,
        model: 'echo-v1',
        finishReason: 'stop',
      },
    };
  }
}
